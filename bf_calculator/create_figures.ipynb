{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"data/\"\n",
    "path_to_scripts = \"scripts/\"\n",
    "path_to_images = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53553ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Figure 1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Show the added read values for high and low read simulations\n",
    "\n",
    "N = np.linspace(100,1000,20)\n",
    "q = np.linspace(0.00001, 0.05, 20)\n",
    "\n",
    "x, y = np.meshgrid(N, q, indexing='ij')\n",
    "z = x * y * 4\n",
    "plt.pcolor(x,y,z,shading='auto')\n",
    "plt.colorbar(label=\"Added mobile reads\")\n",
    "plt.xlabel(\"N\")\n",
    "plt.ylabel(\"q\")\n",
    "plt.savefig(path_to_images + \"added_reads.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea542a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure 2: Evaluating using absolute reads to determine mobility\n",
    "\n",
    "## Run the simulations\n",
    "\n",
    "#!python scripts/simulations.py\n",
    "!python scripts/simulations_hom1000.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/N_q_sims.rep_0hom1000.csv\")\n",
    "df_mob = df[df[\"mobile\"]==True]\n",
    "df_mob.sort_values([\"N\",\"q\"])[[\"N\",\"q\",\"eco2\",\"Nhomo1\",\"nhomo1\",\"Nhomo2\",\"nhomo2\",\"log10BF\"]].to_csv(\"dfmob_hom1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11205b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the absolute analysis\n",
    "!python scripts/plot_abs_reads.py\n",
    "!python scripts/plot_universal_reads.py\n",
    "!python scripts/plot_bayes_reads.py\n",
    "!python scripts/plot_bayes_added_reads.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c885dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the simulations for the Bayes analysis with the different added mobile reads\n",
    "## Uncomment to run - this is slow!\n",
    "#!python3 scripts/bayes_added_reads.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the simulations for the Bayes analysis with the different added mobile reads\n",
    "!python3 scripts/plot_bayes_added_reads.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db326811",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run differences between mobile and nonmobile populations\n",
    "!python3 scripts/mobile_nonmobile_diff.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python3 scripts/plot_mobile_nonmobile_diff.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an accuracy plot for the simulation output\n",
    "#Precision = True Positive/Predicted Positive\n",
    "#Recall = True Positive/ Actual Positive\n",
    "# F1 = 2 * (precision * recall) / (precision + recall)\n",
    "!python scripts/plot_accuracy_bayes.py\n",
    "!python scripts/plot_accuracy_universal.py\n",
    "!python scripts/plot_accuracy_abs.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"data/\"\n",
    "path_to_output = \"images/\"\n",
    "df1 = pd.read_csv(path_to_data + \"N_q_sims.rep_0.csv\")\n",
    "df2 = pd.read_csv(path_to_data +\"N_q_sims.rep_1.csv\")\n",
    "\n",
    "## Apply data caps\n",
    "df1[\"log10BF\"].loc[df1[\"log10BF\"]>2]= 2\n",
    "df1[\"log10BF\"].loc[df1[\"log10BF\"]<-2]= -2\n",
    "df2[\"log10BF\"].loc[df2[\"log10BF\"]>2]= 2\n",
    "df2[\"log10BF\"].loc[df2[\"log10BF\"]<-2]= -2\n",
    "\n",
    "## Change datapoints where mobile transcripts have no reads mapping to the other ecotype\n",
    "df1[\"mobile\"].loc[(df1[\"mobile\"]==True) & (df1[\"n_mobile\"]==0)]=False\n",
    "df2[\"mobile\"].loc[(df2[\"mobile\"]==True) & (df2[\"n_mobile\"]==0)]=False\n",
    "\n",
    "## Sum the Bayes factor\n",
    "df_bayes = df1\n",
    "df_bayes[\"log10BF\"] = df1[\"log10BF\"] + df2[\"log10BF\"]\n",
    "\n",
    "test = df_bayes.loc[(df_bayes[\"q\"]<0.01) * (df_bayes[\"N\"]<200)]\n",
    "test = test[[\"mobile\",\"N\",\"q\",\"n_mobile\",\"Nhomo1\",\"nhomo1\",\"Nhomo2\",\"nhomo2\",\"log10BF\"]]\n",
    "test.loc[test[\"mobile\"]==True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d39ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/plot_accuracy_bayes_hom1000.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script to run the code for the main simulations to be analysed by the 3 methods\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "## Simulations that only create heterograft data and usse the average error rate as the prior\n",
    "\n",
    "## Bayes factors code\n",
    "## Define the main functions\n",
    "\n",
    "def safebeta(N,n, alpha,beta):\n",
    "    facterm = 1.0\n",
    "    if alpha>1:\n",
    "        a = np.arange(1, alpha)\n",
    "        facterm = np.prod((n+a)/(N+a))\n",
    "    if beta > 1.0:\n",
    "        a = np.arange(1, beta)\n",
    "        facterm = facterm * np.prod((N-n+a)/(N+alpha+a))\n",
    "    return facterm / (N+alpha)\n",
    "\n",
    "safebeta = np.vectorize(safebeta)\n",
    "\n",
    "## Function to calculate the posterior ratio\n",
    "def fasterpostN2(Nhomo1,nhomo1,Nhomo2,nhomo2,N,n,nmax):\n",
    "    N = int(N)\n",
    "    alpha1 = nhomo1+1\n",
    "    beta1 = Nhomo1-nhomo1+1\n",
    "    alpha2 = nhomo2+1\n",
    "    beta2 = Nhomo2-nhomo2+1\n",
    "    postN2 = np.zeros(N+2)\n",
    "    postN2xN2 = np.zeros(N+2)\n",
    "    PN2max = -10.0\n",
    "    N2max = 0\n",
    "    for N2 in np.arange(0,min(N+1,n+nmax+1)):\n",
    "        N2 = int(N2)\n",
    "        i = N2 + 1\n",
    "        n2_min = max(0,N2-n)\n",
    "        n2_max = min(N-n, N2)\n",
    "        n2_array = np.arange(n2_min, n2_max+1)\n",
    "        postN2[i] = np.sum(safebeta(N-N2,n-N2+n2_array,alpha1,beta1) * safebeta(N2,n2_array,alpha2,beta2))\n",
    "        postN2[i]=postN2[i]/i\n",
    "        if (N2>0) & (postN2[i]>PN2max):\n",
    "            PN2max = postN2[i]\n",
    "            N2max = N2\n",
    "        \n",
    "        postN2xN2[i]=postN2[i]*N2\n",
    "    \n",
    "    sumpostN2=sum(postN2)\n",
    "    if sumpostN2 != 0:\n",
    "        postN2=postN2/sumpostN2\n",
    "        postN2xN2=postN2xN2/sumpostN2\n",
    "        logBF21N2 = np.log10(postN2[N2max+1]/postN2[1]) # +1 because of the index\n",
    "        meanN2=sum(postN2xN2)\n",
    "        results = [meanN2,N2max,logBF21N2]\n",
    "        results = logBF21N2\n",
    "    else:\n",
    "        ## If sumpost = 0, can't calculate BF. Return nan\n",
    "         results = [np.nan, np.nan, np.nan]\n",
    "         results = np.nan\n",
    "    return results\n",
    "\n",
    "## Reads to add to mobile SNPs\n",
    "mobile_add = 4\n",
    "\n",
    "## Define the functions\n",
    "## Create reads function\n",
    "def create_reads(row, q):\n",
    "    rand_numbs = np.random.rand(int(row))\n",
    "    nhom1 = (rand_numbs < q).sum()\n",
    "    return int(nhom1)\n",
    "\n",
    "## Function to assign transported SNP reads\n",
    "def mobile_reads(N, mobile, q,mobile_add):\n",
    "    range = mobile_add * (q * N)\n",
    "    mob_reads = range * mobile\n",
    "    return int(mob_reads)\n",
    "\n",
    "## Define parameters\n",
    "transcript_no = 100\n",
    "\n",
    "## Het reads\n",
    "## Create the dataframes\n",
    "N = np.random.uniform(low = 10, high = 1000, size = transcript_no)\n",
    "q = np.random.uniform(low = 0.0, high = 0.1, size = transcript_no)\n",
    "tp_list = []\n",
    "tn_list = []\n",
    "fp_list = []\n",
    "fn_list = []\n",
    "## Replicates to calculate ROC-AUC\n",
    "bf_thresh = np.linspace(-1,1, 10)\n",
    "for thresh in bf_thresh:\n",
    "    df = pd.DataFrame([N,q])\n",
    "    df=df.T\n",
    "    df.columns=[\"N\",\"q\"]\n",
    "\n",
    "    ## Calculate the average error \n",
    "    av_error = np.mean(q)\n",
    "    ## Run analysis for each value\n",
    "    df['eco2'] = df[['N','q']].apply(lambda x: create_reads(*x),axis=1)\n",
    "    df[\"mobile\"] = random.choices([True, False], weights=[0.5, 0.5], k=transcript_no)\n",
    "    df['n_mobile'] = df[[\"N\", \"mobile\", \"q\"]].apply(lambda x: mobile_reads(*x,mobile_add), axis=1)\n",
    "    ## Add an extra read to make sure there are no zero values\n",
    "    df[\"n_mobile\"].loc[df[\"mobile\"]==True] += 1\n",
    "    df[\"eco2\"] = df[\"eco2\"] + df[\"n_mobile\"]\n",
    "    ## Assume well-defined error rates\n",
    "    Nhomo1 = int(1000 * (1 - av_error))\n",
    "    nhomo1 = int(1000 * av_error)\n",
    "    Nhomo2 = int(1000 * (1 - av_error))\n",
    "    nhomo2 = int(1000 * av_error)\n",
    "    df[\"log10BF\"] = df[[\"N\",\"eco2\"]].apply(lambda x: fasterpostN2(Nhomo1, nhomo1, Nhomo2, nhomo2, *x, 10), axis=1)\n",
    "    ## Sum the Bayes factor\n",
    "    df_bayes = df\n",
    "    #df_bayes[\"log10BF\"] = df1[\"log10BF\"] + df2[\"log10BF\"]\n",
    "\n",
    "    df_bayes[\"TP\"] = 0\n",
    "    df_bayes[\"TN\"] = 0\n",
    "    df_bayes[\"FP\"] = 0\n",
    "    df_bayes[\"FN\"] = 0\n",
    "\n",
    "    ## Bayesian analysis\n",
    "    df_bayes[\"TP\"].loc[(df_bayes[\"mobile\"]==True) & (df_bayes[\"log10BF\"]>=thresh)] = 1\n",
    "    df_bayes[\"TN\"].loc[(df_bayes[\"mobile\"]==False) & (df_bayes[\"log10BF\"]<thresh)] = 1\n",
    "    df_bayes[\"FN\"].loc[(df_bayes[\"mobile\"]==True) & (df_bayes[\"log10BF\"]<thresh)] = 1\n",
    "    df_bayes[\"FP\"].loc[(df_bayes[\"mobile\"]==False) & (df_bayes[\"log10BF\"]>=thresh)] = 1\n",
    "\n",
    "    TP = df_bayes[\"TP\"].sum()\n",
    "    TN = df_bayes[\"TN\"].sum()\n",
    "    FP = df_bayes[\"FP\"].sum()\n",
    "    FN = df_bayes[\"FN\"].sum()\n",
    "\n",
    "\n",
    "    tp_list.append(TP)\n",
    "    tn_list.append(TN)\n",
    "    fp_list.append(FP)\n",
    "    fn_list.append(FN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TPR y\n",
    "## FPR x\n",
    "\n",
    "tpr = np.array(tp_list) / (np.array(tp_list) + np.array(fn_list))\n",
    "fpr = np.array(fp_list) / (np.array(fp_list) + np.array(tn_list))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fpr,tpr,'x')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f810832",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tpr)\n",
    "display(fpr)\n",
    "display(bf_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ca3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run z-score analysis on the simulation data\n",
    "## Get average error rates across all homograft datasets\n",
    "## Plot individual error rates against each other for each SNP / exp - are the ones with the high BFs consistent in errors?\n",
    "from os import listdir, mkdir, getcwd\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "\n",
    "## Load in all of the homograft data\n",
    "hompath = \"../mrna-data-mining/bayesian_SNPs/raw_data/col_ler/homfiles/\"\n",
    "homfiles = [f for f in listdir(hompath) if isfile(join(hompath, f))]\n",
    "homfiles = [f for f in homfiles if \"Store\" not in f]\n",
    "col_hom = [f for f in homfiles if \"Col\" in f]\n",
    "ler_hom = [f for f in homfiles if \"Ler\" in f]\n",
    "display(homfiles)\n",
    "\n",
    "error_list = []\n",
    "## load in and calculate error rates\n",
    "for f in col_hom:\n",
    "    df = pd.read_csv(hompath + f, delimiter=\"\\t\")\n",
    "    df = df[[\"colDepth\",\"lerDepth\",\"depth\"]]\n",
    "    df[[\"colDepth\",\"lerDepth\",\"depth\"]] = df[[\"colDepth\",\"lerDepth\",\"depth\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df = df.loc[df[\"depth\"]>0]\n",
    "    df.dropna(inplace = True)\n",
    "    df[\"error\"] = (df[\"lerDepth\"] + 1) / (df[\"depth\"]  + 2)\n",
    "    error_list.append(df[\"error\"].mean())\n",
    "\n",
    "error_list  = np.array(error_list)\n",
    "print(error_list.mean())\n",
    "print(error_list.std())\n",
    "\n",
    "error_list=[]\n",
    "for f in ler_hom:\n",
    "    df = pd.read_csv(hompath + f, delimiter=\"\\t\")\n",
    "    df = df[[\"colDepth\",\"lerDepth\",\"depth\"]]\n",
    "    df[[\"colDepth\",\"lerDepth\",\"depth\"]] = df[[\"colDepth\",\"lerDepth\",\"depth\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df = df.loc[df[\"depth\"]>0]\n",
    "    df.dropna(inplace = True)\n",
    "    df[\"error\"] = (df[\"colDepth\"] + 1) / (df[\"depth\"]  + 2)\n",
    "    error_list.append(df[\"error\"].mean())\n",
    "\n",
    "\n",
    "error_list  = np.array(error_list)\n",
    "print(error_list.mean())\n",
    "print(error_list.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the errors\n",
    "col_hom_stem = [f for f in col_hom if \"Stem\" in f]\n",
    "col_hom_stem\n",
    "\n",
    "df1 = pd.read_csv(hompath + col_hom_stem[0], delimiter = \"\\t\", low_memory = False)\n",
    "df2 = pd.read_csv(hompath + col_hom_stem[1], delimiter = \"\\t\", low_memory = False)\n",
    "df1[[\"colDepth\",\"lerDepth\",\"depth\"]] = df1[[\"colDepth\",\"lerDepth\",\"depth\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "df1.dropna(inplace = True)\n",
    "d1 = df1.loc[df1[\"depth\"]>0]\n",
    "\n",
    "df2[[\"colDepth\",\"lerDepth\",\"depth\"]] = df2[[\"colDepth\",\"lerDepth\",\"depth\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "df2.dropna(inplace = True)\n",
    "df2 = df2.loc[df2[\"depth\"]>0]\n",
    "\n",
    "df_stem = pd.merge(df1, df2, on=\"SNP\")\n",
    "df_stem[\"error1\"] = (df_stem[\"lerDepth_x\"] + 1) / (df_stem[\"depth_x\"] + 2)\n",
    "df_stem[\"error2\"] = (df_stem[\"lerDepth_y\"] + 1) / (df_stem[\"depth_y\"] + 2)\n",
    "\n",
    "plt.plot(df_stem[\"error1\"], df_stem[\"error2\"],'x')\n",
    "plt.xlabel(\"Error rep1\")\n",
    "plt.ylabel(\"Error rep2\")\n",
    "plt.title(\"Stem\")\n",
    "plt.savefig(\"stem_error.png\",dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "col_hom_rosette = [f for f in col_hom if \"Rosette\" in f]\n",
    "\n",
    "df1 = pd.read_csv(hompath + col_hom_rosette[0], delimiter = \"\\t\", low_memory = False)\n",
    "df2 = pd.read_csv(hompath + col_hom_rosette[1], delimiter = \"\\t\", low_memory = False)\n",
    "df1[[\"colDepth\",\"lerDepth\",\"depth\"]] = df1[[\"colDepth\",\"lerDepth\",\"depth\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "df1.dropna(inplace = True)\n",
    "df1 = df1.loc[df1[\"depth\"]>0]\n",
    "\n",
    "df2[[\"colDepth\",\"lerDepth\",\"depth\"]] = df2[[\"colDepth\",\"lerDepth\",\"depth\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "df2.dropna(inplace = True)\n",
    "\n",
    "df_rosette = pd.merge(df1, df2, on=\"SNP\")\n",
    "df_rosette[\"error1\"] = (df_rosette[\"lerDepth_x\"] + 1) / (df_rosette[\"depth_x\"] + 2)\n",
    "df_rosette[\"error2\"] = (df_rosette[\"lerDepth_y\"] + 1) / (df_rosette[\"depth_y\"] + 2)\n",
    "\n",
    "plt.plot(df_rosette[\"error1\"], df_rosette[\"error2\"],'x')\n",
    "plt.xlabel(\"Error rep1\")\n",
    "plt.ylabel(\"Error rep2\")\n",
    "plt.title(\"Rosette\")\n",
    "plt.savefig(\"rosette_error.png\",dpi=300)\n",
    "plt.show()\n",
    "\n",
    "col_hom_flower = [f for f in col_hom if \"Flower\" in f]\n",
    "\n",
    "df1 = pd.read_csv(hompath + col_hom_flower[0], delimiter = \"\\t\", low_memory = False)\n",
    "df2 = pd.read_csv(hompath + col_hom_flower[1], delimiter = \"\\t\", low_memory = False)\n",
    "df1[[\"colDepth\",\"lerDepth\",\"depth\"]] = df1[[\"colDepth\",\"lerDepth\",\"depth\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "df1.dropna(inplace = True)\n",
    "df1 = df1.loc[df1[\"depth\"]>0]\n",
    "\n",
    "df2[[\"colDepth\",\"lerDepth\",\"depth\"]] = df2[[\"colDepth\",\"lerDepth\",\"depth\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "df2.dropna(inplace = True)\n",
    "df2 = df2.loc[df2[\"depth\"]>0]\n",
    "\n",
    "df_flower = pd.merge(df1, df2, on=\"SNP\")\n",
    "df_flower[\"error1\"] = (df_flower[\"lerDepth_x\"] + 1) / (df_flower[\"depth_x\"] + 2)\n",
    "df_flower[\"error2\"] = (df_flower[\"lerDepth_y\"] + 1) / (df_flower[\"depth_y\"] + 2)\n",
    "\n",
    "plt.plot(df_flower[\"error1\"], df_flower[\"error2\"],'x')\n",
    "\n",
    "plt.title(\"Flower\")\n",
    "plt.xlabel(\"Error rep1\")\n",
    "plt.ylabel(\"Error rep2\")\n",
    "plt.savefig(\"flower_error.png\",dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/plot_zscores.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adae8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/simulations_hom_10.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python scripts/plot_zscores_hom10.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/plot_zscores.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### What difference does taking only the \"best\" SNPs make?\n",
    "\n",
    "## Create the simulated data: added in a high level of noise, and different error rates for each SNP in a transcript\n",
    "\n",
    "## Select the \"best\" 1/2/3/4/5 etc SNPs and see how that changes the results\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "transcripts = 1000\n",
    "\n",
    "## Create a dataframe of transcripts\n",
    "transcript_ids = []\n",
    "\n",
    "for t in range(transcripts):\n",
    "    transcript_ids.append(\"Transcript_\"+str(t))\n",
    "\n",
    "df = pd.DataFrame(data=transcript_ids, columns=[\"transcripts\"])\n",
    "\n",
    "## Create columns for each SNP\n",
    "no_snps = 100\n",
    "\n",
    "## Create matrix of error rates\n",
    "errors = np.random.rand(transcripts, no_snps) / 10 ## errors between 0 and 0.1\n",
    "errors = np.ones([transcripts, no_snps]) * 0.01\n",
    "## Create matrix of read depths\n",
    "reads = np.random.randint(low = 1, high=100, size=[transcripts, no_snps])\n",
    "\n",
    "## Create matrix of ns\n",
    "def create_reads(row, q):\n",
    "    rand_numbs = np.random.rand(int(row))\n",
    "    nhom1 = (rand_numbs < q).sum()\n",
    "    return int(nhom1)\n",
    "\n",
    "## Function to assign transported SNP reads\n",
    "def mobile_reads(N, mobile, q,mobile_add):\n",
    "    range = mobile_add * (q * N)\n",
    "    mob_reads = range * mobile\n",
    "    return int(mob_reads)\n",
    "\n",
    "create_reads = np.vectorize(create_reads)\n",
    "mobile_reads = np.vectorize(mobile_reads)\n",
    "\n",
    "ns = create_reads(reads, errors)\n",
    "\n",
    "## Create mobile values\n",
    "\n",
    "## Add on mobile reads\n",
    "mobile_add = 5\n",
    "mobile_def = random.choices([True, False], weights=[0.5, 0.5], k=transcripts)\n",
    "mobile_def = np.repeat(mobile_def,no_snps)\n",
    "mobile = mobile_def.reshape(transcripts, no_snps)\n",
    "\n",
    "n_mobs = mobile_reads(reads, mobile, errors, mobile_add)\n",
    "ns = ns + n_mobs\n",
    "\n",
    "## Create homograft data using the same error rates\n",
    "hom1_reads = np.random.randint(low = 1, high=100, size=[transcripts, no_snps])\n",
    "hom2_reads = np.random.randint(low = 1, high=100, size=[transcripts, no_snps])\n",
    "hom1_n = create_reads(hom1_reads, errors)\n",
    "hom2_n = create_reads(hom2_reads, errors)\n",
    "\n",
    "## Create the dataframe of Bayes Factors\n",
    "## Add in the functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "\n",
    "## Define the main functions\n",
    "def safebeta(N,n, alpha,beta):\n",
    "    facterm = 1.0\n",
    "    if alpha>1:\n",
    "        a = np.arange(1, alpha)\n",
    "        facterm = np.prod((n+a)/(N+a))\n",
    "    if beta > 1.0:\n",
    "        a = np.arange(1, beta)\n",
    "        facterm = facterm * np.prod((N-n+a)/(N+alpha+a))\n",
    "    return facterm / (N+alpha)\n",
    "\n",
    "safebeta = np.vectorize(safebeta)\n",
    "\n",
    "## Function to calculate the posterior ratio\n",
    "def fasterpostN2(Nhomo1,nhomo1,Nhomo2,nhomo2,N,n,nmax):\n",
    "    N = int(N)\n",
    "    alpha1 = nhomo1+1\n",
    "    beta1 = Nhomo1-nhomo1+1\n",
    "    alpha2 = nhomo2+1\n",
    "    beta2 = Nhomo2-nhomo2+1\n",
    "    postN2 = np.zeros(N+2)\n",
    "    postN2xN2 = np.zeros(N+2)\n",
    "    PN2max = -10.0\n",
    "    N2max = 0\n",
    "    for N2 in np.arange(0,min(N+1,n+nmax+1)):\n",
    "        N2 = int(N2)\n",
    "        i = N2 + 1\n",
    "        n2_min = max(0,N2-n)\n",
    "        n2_max = min(N-n, N2)\n",
    "        n2_array = np.arange(n2_min, n2_max+1)\n",
    "        postN2[i] = np.sum(safebeta(N-N2,n-N2+n2_array,alpha1,beta1) * safebeta(N2,n2_array,alpha2,beta2))\n",
    "        postN2[i]=postN2[i]/i\n",
    "        if (N2>0) & (postN2[i]>PN2max):\n",
    "            PN2max = postN2[i]\n",
    "            N2max = N2\n",
    "        \n",
    "        postN2xN2[i]=postN2[i]*N2\n",
    "    \n",
    "    sumpostN2=sum(postN2)\n",
    "    if sumpostN2 != 0:\n",
    "        postN2=postN2/sumpostN2\n",
    "        postN2xN2=postN2xN2/sumpostN2\n",
    "        logBF21N2 = np.log10(postN2[N2max+1]/postN2[1]) # +1 because of the index\n",
    "        meanN2=sum(postN2xN2)\n",
    "        results = [meanN2,N2max,logBF21N2]\n",
    "        results = logBF21N2\n",
    "    else:\n",
    "        ## If sumpost = 0, can't calculate BF. Return nan\n",
    "         results = [np.nan, np.nan, np.nan]\n",
    "         results = np.nan\n",
    "    return results\n",
    "fasterpostN2 = np.vectorize(fasterpostN2)\n",
    "\n",
    "## Iterate through every value in the dataframes\n",
    "bfs = fasterpostN2(hom1_reads,hom1_n,hom2_reads,hom2_n,reads,ns,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabdf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create results using all the SNPs\n",
    "\n",
    "summed_bfs = bfs.sum(axis=1)\n",
    "#summed_bfs[np.isnan(summed_bfs)] = 20\n",
    "#summed_bfs[np.isinf(summed_bfs)] = -2\n",
    "mobile_list = mobile[:,0]\n",
    "tp = summed_bfs[(summed_bfs>=1) & (mobile_list==True) ]\n",
    "tn = summed_bfs[(summed_bfs<1) & (mobile_list==False) ]\n",
    "fp = summed_bfs[(summed_bfs>=1) & (mobile_list==False)]\n",
    "fn = summed_bfs[(summed_bfs<1) & (mobile_list==True) ]\n",
    "\n",
    "print(len(tp), len(tn), len(fp), len(fn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eedaee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af79acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can we improve this by only taking the best SNPs in the homograft data?\n",
    "## Let's start with just the N values - choose the best from both homografts\n",
    "\n",
    "## Check all of the different SNP combinations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "snps = range(100)\n",
    "\n",
    "test_hom = hom1_reads.copy()\n",
    "\n",
    "for snp in snps:\n",
    "    new_bfs = []\n",
    "    for i in range(1000):\n",
    "        args = np.argpartition(test_hom[i], -snp)[-snp:]\n",
    "        new_bfs.append(bfs[i,args].sum())\n",
    "\n",
    "    new_bfs = np.array(new_bfs)\n",
    "    new_bfs[np.isinf(new_bfs)] = 20\n",
    "    new_bfs[np.isnan(new_bfs)] = -2\n",
    "    mobile_list = mobile[:,0]\n",
    "    tp = new_bfs[(new_bfs>=1) & (mobile_list==True) ]\n",
    "    tn = new_bfs[(new_bfs<1) & (mobile_list==False) ]\n",
    "    fp = new_bfs[(new_bfs>=1) & (mobile_list==False)]\n",
    "    fn = new_bfs[(new_bfs<1) & (mobile_list==True) ]\n",
    "\n",
    "    print(len(tp), len(tn), len(fp), len(fn))\n",
    "    print(\"TPR\")\n",
    "    tpr = len(tp)/(len(tp)+len(fn))\n",
    "    plt.plot(snp, tpr, 'kx')\n",
    "plt.xlabel(\"SNPs\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.savefig(\"snps_summed.png\",dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hom = hom1_reads.copy()\n",
    "hom_total = hom1_reads + hom2_reads\n",
    "new_bfs = []\n",
    "for i in range(1000):\n",
    "    #test = np.stack((hom1_reads[i],hom2_reads[i]),axis=1)\n",
    "    args = np.argpartition(hom_total[i], -3)[-3:]\n",
    "    new_bfs.append(bfs[i,args].sum())\n",
    "\n",
    "new_bfs = np.array(new_bfs)\n",
    "new_bfs[np.isnan(new_bfs)] = 20\n",
    "new_bfs[np.isinf(new_bfs)] = -2\n",
    "mobile_list = mobile[:,0]\n",
    "tp = new_bfs[(new_bfs>=1) & (mobile_list==True) ]\n",
    "tn = new_bfs[(new_bfs<1) & (mobile_list==False) ]\n",
    "fp = new_bfs[(new_bfs>=1) & (mobile_list==False)]\n",
    "fn = new_bfs[(new_bfs<1) & (mobile_list==True) ]\n",
    "\n",
    "print(len(tp), len(tn), len(fp), len(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3182301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "snps = range(100)\n",
    "\n",
    "test_hom = hom1_reads.copy()\n",
    "test_bfs = bfs.copy()\n",
    "print(np.shape(test_hom))\n",
    "x,y = np.where(test_hom>50)\n",
    "print(test_hom[x,y])\n",
    "test_bfs = test_bfs[test_hom>50]\n",
    "test_hom = test_hom[test_hom>50]\n",
    "print(np.shape(test_hom))\n",
    "\n",
    "test_bfs[np.isinf(test_bfs)] = 20\n",
    "test_bfs[np.isnan(test_bfs)] = -2\n",
    "mobile_list = mobile[:,0]\n",
    "\n",
    "\n",
    "tp = new_bfs[(new_bfs>=1) & (mobile_list==True) ]\n",
    "tn = new_bfs[(new_bfs<1) & (mobile_list==False) ]\n",
    "fp = new_bfs[(new_bfs>=1) & (mobile_list==False)]\n",
    "fn = new_bfs[(new_bfs<1) & (mobile_list==True) ]\n",
    "\n",
    "print(len(tp), len(tn), len(fp), len(fn))\n",
    "print(\"TPR\")\n",
    "tpr = len(tp)/(len(tp)+len(fn))\n",
    "plt.plot(snp, tpr, 'kx')\n",
    "plt.xlabel(\"SNPs\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.savefig(\"snps_summed_cutoff.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19688613",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the final results plots for the paper\n",
    "\n",
    "N = 100\n",
    "q = 0.01\n",
    "\n",
    "## Can't use  different values of N2 as that only covers the mobile transcripts. Doh!\n",
    "\n",
    "## Use different values of SNPs - just create all of the values at once though.\n",
    "\n",
    "no_SNPs = 20\n",
    "\n",
    "## Create the dataframe\n",
    "transcripts = 1000\n",
    "\n",
    "## Create list of dataframes\n",
    "df_list = []\n",
    "\n",
    "## Create the mobile transcripts - same for each dataframe\n",
    "mobile_def = random.choices([True, False], weights=[0.5, 0.5], k=transcripts)\n",
    "\n",
    "## Function to create sequencing errors\n",
    "def create_errors(row, q):\n",
    "        rand_numbs = np.random.rand(int(row))\n",
    "        nhom1 = (rand_numbs < q).sum()\n",
    "        return int(nhom1)\n",
    "\n",
    "## Create the homograft datasets\n",
    "Nhom1 = np.random.randint(low = 10, high = 100, size = transcripts)\n",
    "Nhom2 = np.random.randint(low = 10, high = 100, size = transcripts)\n",
    "\n",
    "for snp in range(no_SNPs):\n",
    "\n",
    "    ## Create the heterograft datasets\n",
    "    \n",
    "    Nhet = np.random.randint(low = 10, high = 100, size = transcripts)\n",
    "    df = pd.DataFrame([Nhom1, Nhom2, Nhet, mobile_def])\n",
    "    df = df.T\n",
    "    df.columns = [\"Nhom1\",\"Nhom2\",\"Nhet\",\"mobile\"]\n",
    "    df[\"N2\"] = 5\n",
    "\n",
    "    ## Create the sequencing errors\n",
    "\n",
    "    df[\"nhom1\"] = df[\"Nhom1\"].apply(lambda x: create_errors(x, q))\n",
    "    df[\"nhom2\"] = df[\"Nhom2\"].apply(lambda x: create_errors(x, q))\n",
    "    df[\"n\"] = df[\"Nhet\"].apply(lambda x: create_errors(x, q))\n",
    "    df[\"N2\"] = df[\"N2\"] * df[\"mobile\"]\n",
    "\n",
    "    df[\"n\"] = df[\"n\"] + df[\"N2\"]\n",
    "\n",
    "    ## Run Bayes analysis\n",
    "    df[\"log10BF\"] = df.apply(lambda x: fasterpostN2(x.Nhom1,x.nhom1,x.Nhom2,x.nhom2,x.Nhet,x.n,10), axis=1)\n",
    "    df_list.append(df)\n",
    "\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "## Plot the accuracy for each number of SNPs\n",
    "for snp in np.arange(1,20):\n",
    "    dfs = df_list[0:snp]\n",
    "\n",
    "    ## Classification requires positive identification in all SNPs\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i][\"abs\"] = dfs[i][\"n\"]\n",
    "        dfs[i][\"abs\"][dfs[i][\"abs\"]>0] = 1\n",
    "\n",
    "    ## Add together the dataframes\n",
    "    this_df = reduce(lambda x, y: x.add(y, fill_value=0), dfs)\n",
    "    this_df[\"abs\"][this_df[\"abs\"]==len(dfs)] = 1\n",
    "    this_df[\"abs\"][this_df[\"abs\"]<len(dfs)] = 0\n",
    "    \n",
    "    this_df[\"TP_bf\"] = 0\n",
    "    this_df[\"TN_bf\"] = 0\n",
    "    this_df[\"FP_bf\"] = 0\n",
    "    this_df[\"FN_bf\"] = 0\n",
    "\n",
    "    this_df[\"TP_class\"] = 0\n",
    "    this_df[\"TN_class\"] = 0\n",
    "    this_df[\"FP_class\"] = 0\n",
    "    this_df[\"FN_class\"] = 0\n",
    "\n",
    "    this_df[\"TP_bf\"].loc[(this_df[\"log10BF\"]>=1) & (this_df[\"mobile\"] > 0)] = 1\n",
    "    this_df[\"TN_bf\"].loc[(this_df[\"log10BF\"]<1) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FP_bf\"].loc[(this_df[\"log10BF\"]>=1) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FN_bf\"].loc[(this_df[\"log10BF\"]<1) & (this_df[\"mobile\"] > 0)] = 1\n",
    "\n",
    "    this_df[\"TP_class\"].loc[(this_df[\"abs\"]>0) & (this_df[\"mobile\"] > 0)] = 1\n",
    "    this_df[\"TN_class\"].loc[(this_df[\"abs\"]==0) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FP_class\"].loc[(this_df[\"abs\"]==0) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FN_class\"].loc[(this_df[\"abs\"]<0) & (this_df[\"mobile\"] > 0)] = 1\n",
    "\n",
    "    ## For the universal pipeline method, remove all values with non-zeros counts in the homograft data\n",
    "    cutoff = 1\n",
    "    for df_u in dfs:\n",
    "        df_u[\"universal\"] = 0\n",
    "        df_u[\"universal\"].loc[df_u[\"n\"]>cutoff]=1\n",
    "        df_u[\"universal\"].loc[(df_u[\"nhom1\"]>0)|(df_u[\"nhom2\"]>0)]=0\n",
    "\n",
    "    ## Has to be identified in two replicates\n",
    "    df_u_main = df_list[0]\n",
    "    df_list_summed = reduce(lambda x, y: x.add(y, fill_value=0), dfs)\n",
    "    df_u_main[\"universal_summed\"] = df_list_summed[\"universal\"]\n",
    "    ## Calculate TP, TN, FP, FN\n",
    "    df_u_main[\"TP\"] = 0\n",
    "    df_u_main[\"TN\"] = 0\n",
    "    df_u_main[\"FP\"] = 0\n",
    "    df_u_main[\"FN\"] = 0\n",
    "\n",
    "    df_u_main[\"TP\"].loc[(df_u_main[\"mobile\"]==True) & (df_u_main[\"universal_summed\"]==len(dfs))] = 1\n",
    "    df_u_main[\"TN\"].loc[(df_u_main[\"mobile\"]==False) & (df_u_main[\"universal_summed\"]<len(dfs))] = 1\n",
    "    df_u_main[\"FN\"].loc[(df_u_main[\"mobile\"]==True) & (df_u_main[\"universal_summed\"]<len(dfs))] = 1\n",
    "    df_u_main[\"FP\"].loc[(df_u_main[\"mobile\"]==False) & (df_u_main[\"universal_summed\"]==len(dfs))] = 1\n",
    "\n",
    "    tp = this_df[\"TP_bf\"].sum()\n",
    "    fp = this_df[\"FP_bf\"].sum()\n",
    "    tn = this_df[\"TN_bf\"].sum()\n",
    "    fn = this_df[\"FN_bf\"].sum()\n",
    "    bf_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(snp, bf_accuracy,\"kx\")\n",
    "\n",
    "    tp = this_df[\"TP_class\"].sum()\n",
    "    fp = this_df[\"FP_class\"].sum()\n",
    "    tn = this_df[\"TN_class\"].sum()\n",
    "    fn = this_df[\"FN_class\"].sum()\n",
    "    abs_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(snp, abs_accuracy,\"rx\")\n",
    "\n",
    "    tp = df_u_main[\"TP\"].sum()\n",
    "    fp = df_u_main[\"FP\"].sum()\n",
    "    tn = df_u_main[\"TN\"].sum()\n",
    "    fn = df_u_main[\"FN\"].sum()\n",
    "    uni_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(snp, uni_accuracy,\"bx\")\n",
    "\n",
    "plt.plot(snp, bf_accuracy, \"kx\", label = \"BF\")\n",
    "plt.plot(snp, abs_accuracy, \"rx\", label = \"Method A\")\n",
    "plt.plot(snp, uni_accuracy, \"bx\",label = \"Method B\")\n",
    "\n",
    "plt.xlabel(\"No of SNPs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlim(0,20)\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(np.arange(0, 20, step=2)) \n",
    "plt.legend()\n",
    "plt.savefig(\"accuracy_comp.png\",dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change Method A and Method B so that they only require N SNPs\n",
    "\n",
    "req_SNPs = 2\n",
    "\n",
    "from functools import reduce\n",
    "## Plot the accuracy for each number of SNPs\n",
    "for snp in np.arange(1,20):\n",
    "    dfs = df_list[0:snp]\n",
    "\n",
    "    ## Classification requires positive identification in all SNPs\n",
    "    for i in range(len(dfs)):\n",
    "        ## Classification\n",
    "        dfs[i][\"abs\"] = dfs[i][\"n\"]\n",
    "        dfs[i][\"abs\"][dfs[i][\"abs\"]>0] = 1\n",
    "\n",
    "        ## Universal pipeline\n",
    "        dfs[i][\"universal\"] = dfs[i][\"n\"]\n",
    "        dfs[i][\"universal\"].loc[dfs[i][\"universal\"]>0]=1\n",
    "        dfs[i][\"universal\"].loc[(dfs[i][\"nhom1\"]>0)|(dfs[i][\"nhom2\"]>0)]=0\n",
    "\n",
    "    ## Add together the dataframes\n",
    "    this_df = reduce(lambda x, y: x.add(y, fill_value=0), dfs)\n",
    "    this_df[\"abs\"][this_df[\"abs\"]<req_SNPs] = 0\n",
    "    this_df[\"abs\"][this_df[\"abs\"]>=req_SNPs] = 1\n",
    "\n",
    "    this_df[\"universal\"][this_df[\"universal\"]<req_SNPs] = 0\n",
    "    this_df[\"universal\"][this_df[\"universal\"]>=req_SNPs] = 1\n",
    "    \n",
    "    this_df[\"TP_bf\"] = 0\n",
    "    this_df[\"TN_bf\"] = 0\n",
    "    this_df[\"FP_bf\"] = 0\n",
    "    this_df[\"FN_bf\"] = 0\n",
    "\n",
    "    this_df[\"TP_class\"] = 0\n",
    "    this_df[\"TN_class\"] = 0\n",
    "    this_df[\"FP_class\"] = 0\n",
    "    this_df[\"FN_class\"] = 0\n",
    "\n",
    "    this_df[\"TP_bf\"].loc[(this_df[\"log10BF\"]>=1) & (this_df[\"mobile\"] > 0)] = 1\n",
    "    this_df[\"TN_bf\"].loc[(this_df[\"log10BF\"]<1) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FP_bf\"].loc[(this_df[\"log10BF\"]>=1) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FN_bf\"].loc[(this_df[\"log10BF\"]<1) & (this_df[\"mobile\"] > 0)] = 1\n",
    "\n",
    "    this_df[\"TP_class\"].loc[(this_df[\"abs\"]>0) & (this_df[\"mobile\"] > 0)] = 1\n",
    "    this_df[\"TN_class\"].loc[(this_df[\"abs\"]==0) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FP_class\"].loc[(this_df[\"abs\"]>0) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FN_class\"].loc[(this_df[\"abs\"]==0) & (this_df[\"mobile\"] > 0)] = 1\n",
    "\n",
    "    ## Calculate TP, TN, FP, FN\n",
    "    this_df[\"TP_universal\"] = 0\n",
    "    this_df[\"TN_universal\"] = 0\n",
    "    this_df[\"FP_universal\"] = 0\n",
    "    this_df[\"FN_universal\"] = 0\n",
    "\n",
    "    this_df[\"TP_universal\"].loc[(this_df[\"mobile\"]>0) & (this_df[\"universal\"]>=req_SNPs)] = 1\n",
    "    this_df[\"TN_universal\"].loc[(this_df[\"mobile\"]==0) & (this_df[\"universal\"]<req_SNPs)] = 1\n",
    "    this_df[\"FN_universal\"].loc[(this_df[\"mobile\"]>0) & (this_df[\"universal\"]<req_SNPs)] = 1\n",
    "    this_df[\"FP_universal\"].loc[(this_df[\"mobile\"]==0) & (this_df[\"universal\"]>=req_SNPs)] = 1\n",
    "\n",
    "    tp = this_df[\"TP_bf\"].sum()\n",
    "    fp = this_df[\"FP_bf\"].sum()\n",
    "    tn = this_df[\"TN_bf\"].sum()\n",
    "    fn = this_df[\"FN_bf\"].sum()\n",
    "    bf_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(snp, bf_accuracy,\"kx\")\n",
    "\n",
    "    tp = this_df[\"TP_class\"].sum()\n",
    "    fp = this_df[\"FP_class\"].sum()\n",
    "    tn = this_df[\"TN_class\"].sum()\n",
    "    fn = this_df[\"FN_class\"].sum()\n",
    "    abs_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(snp, abs_accuracy,\"rx\")\n",
    "\n",
    "    tp = this_df[\"TP_universal\"].sum()\n",
    "    fp = this_df[\"FP_universal\"].sum()\n",
    "    tn = this_df[\"TN_universal\"].sum()\n",
    "    fn = this_df[\"FN_universal\"].sum()\n",
    "    uni_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(snp, uni_accuracy,\"bx\")\n",
    "\n",
    "plt.plot(snp, bf_accuracy, \"kx\", label = \"BF\")\n",
    "plt.plot(snp, abs_accuracy, \"rx\", label = \"Method A\")\n",
    "plt.plot(snp, uni_accuracy, \"bx\",label = \"Method B\")\n",
    "\n",
    "plt.xlabel(\"No of SNPs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlim(0,20)\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(np.arange(0, 20, step=2)) \n",
    "plt.legend()\n",
    "plt.savefig(\"accuracy_req_snps2_error_p01.png\",dpi=300)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb473f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run again for 1 SNP, but different values for q\n",
    "\n",
    "## Create the final results plots for the paper\n",
    "\n",
    "N = 1000\n",
    "qs = np.linspace(0.001,0.01,10)\n",
    "\n",
    "## Create the dataframe\n",
    "transcripts = 1000\n",
    "\n",
    "## Create list of dataframes\n",
    "df_list = []\n",
    "\n",
    "## Create the mobile transcripts - same for each dataframe\n",
    "mobile_def = random.choices([True, False], weights=[0.5, 0.5], k=transcripts)\n",
    "mobile_def = np.repeat(mobile_def, len(qs))\n",
    "\n",
    "## Function to create sequencing errors\n",
    "def create_errors(row, q):\n",
    "        rand_numbs = np.random.rand(int(row))\n",
    "        nhom1 = (rand_numbs < q).sum()\n",
    "        return int(nhom1)\n",
    "\n",
    "## Create the q values\n",
    "qvalues = np.tile(qs, transcripts)\n",
    "\n",
    "## Create the homograft datasets\n",
    "#Nhom1 = np.random.randint(low = 100, high = 100, size = transcripts)\n",
    "#Nhom2 = np.random.randint(low = 100, high = 100, size = transcripts)\n",
    "\n",
    "Nhom1 = np.ones(transcripts) * 1000\n",
    "Nhom2 = np.ones(transcripts) * 1000\n",
    "\n",
    "## Create the heterograft datasets\n",
    "#Nhet = np.random.randint(low = 100, high = 100, size = transcripts)\n",
    "Nhet = np.ones(transcripts) * 1000\n",
    "\n",
    "## Repeat the homograft and heterograft datasets for the qvalues\n",
    "Nhom1 = np.repeat(Nhom1, len(qs))\n",
    "Nhom2 = np.repeat(Nhom2, len(qs))\n",
    "Nhet = np.repeat(Nhet, len(qs))\n",
    "df = pd.DataFrame([Nhom1, Nhom2, Nhet, mobile_def, qvalues])\n",
    "df = df.T\n",
    "df.columns = [\"Nhom1\",\"Nhom2\",\"Nhet\",\"mobile\",\"q\"]\n",
    "df[\"N2\"] = df[\"q\"] * 1000 * 5\n",
    "\n",
    "## Create the sequencing errors\n",
    "\n",
    "df[\"nhom1\"] = df.apply(lambda x: create_errors(x.Nhom1, x.q),axis=1)\n",
    "df[\"nhom2\"] = df.apply(lambda x: create_errors(x.Nhom2, x.q),axis = 1)\n",
    "df[\"n\"] = df.apply(lambda x: create_errors(x.Nhet, x.q), axis = 1)\n",
    "df[\"N2\"] = df[\"N2\"] * df[\"mobile\"]\n",
    "\n",
    "df[\"n\"] = df[\"n\"] + df[\"N2\"]\n",
    "\n",
    "## Run Bayes analysis\n",
    "df[\"log10BF\"] = df.apply(lambda x: fasterpostN2(x.Nhom1,x.nhom1,x.Nhom2,x.nhom2,x.Nhet,x.n,10), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_SNPs = 1\n",
    "## Plot the accuracy for each value for q\n",
    "for q in qs:\n",
    "    print(q)\n",
    "    this_df = df[df[\"q\"] == q]\n",
    "\n",
    "    this_df[\"abs\"] = this_df[\"n\"]\n",
    "    this_df[\"abs\"][this_df[\"abs\"]>0] = 1\n",
    "\n",
    "    ## Universal pipeline\n",
    "    this_df[\"universal\"] = this_df[\"n\"]\n",
    "    this_df[\"universal\"].loc[this_df[\"universal\"]>0]=1\n",
    "    this_df[\"universal\"].loc[(this_df[\"nhom1\"]>0)|(this_df[\"nhom2\"]>0)]=0\n",
    "\n",
    "    this_df[\"TP_bf\"] = 0\n",
    "    this_df[\"TN_bf\"] = 0\n",
    "    this_df[\"FP_bf\"] = 0\n",
    "    this_df[\"FN_bf\"] = 0\n",
    "\n",
    "    this_df[\"TP_class\"] = 0\n",
    "    this_df[\"TN_class\"] = 0\n",
    "    this_df[\"FP_class\"] = 0\n",
    "    this_df[\"FN_class\"] = 0\n",
    "\n",
    "    this_df[\"TP_bf\"].loc[(this_df[\"log10BF\"]>=1) & (this_df[\"mobile\"] > 0)] = 1\n",
    "    this_df[\"TN_bf\"].loc[(this_df[\"log10BF\"]<1) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FP_bf\"].loc[(this_df[\"log10BF\"]>=1) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FN_bf\"].loc[(this_df[\"log10BF\"]<1) & (this_df[\"mobile\"] > 0)] = 1\n",
    "\n",
    "    this_df[\"TP_class\"].loc[(this_df[\"abs\"]>0) & (this_df[\"mobile\"] > 0)] = 1\n",
    "    this_df[\"TN_class\"].loc[(this_df[\"abs\"]==0) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FP_class\"].loc[(this_df[\"abs\"]>0) & (this_df[\"mobile\"] == 0)] = 1\n",
    "    this_df[\"FN_class\"].loc[(this_df[\"abs\"]==0) & (this_df[\"mobile\"] > 0)] = 1\n",
    "\n",
    "    ## Calculate TP, TN, FP, FN\n",
    "    this_df[\"TP_universal\"] = 0\n",
    "    this_df[\"TN_universal\"] = 0\n",
    "    this_df[\"FP_universal\"] = 0\n",
    "    this_df[\"FN_universal\"] = 0\n",
    "\n",
    "    this_df[\"TP_universal\"].loc[(this_df[\"mobile\"]>0) & (this_df[\"universal\"]>=req_SNPs)] = 1\n",
    "    this_df[\"TN_universal\"].loc[(this_df[\"mobile\"]==0) & (this_df[\"universal\"]<req_SNPs)] = 1\n",
    "    this_df[\"FN_universal\"].loc[(this_df[\"mobile\"]>0) & (this_df[\"universal\"]<req_SNPs)] = 1\n",
    "    this_df[\"FP_universal\"].loc[(this_df[\"mobile\"]==0) & (this_df[\"universal\"]>=req_SNPs)] = 1\n",
    "\n",
    "    tp = this_df[\"TP_bf\"].sum()\n",
    "    fp = this_df[\"FP_bf\"].sum()\n",
    "    tn = this_df[\"TN_bf\"].sum()\n",
    "    fn = this_df[\"FN_bf\"].sum()\n",
    "    bf_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(q, bf_accuracy,\"kx\")\n",
    "\n",
    "    tp = this_df[\"TP_class\"].sum()\n",
    "    fp = this_df[\"FP_class\"].sum()\n",
    "    tn = this_df[\"TN_class\"].sum()\n",
    "    fn = this_df[\"FN_class\"].sum()\n",
    "    abs_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(q, abs_accuracy,\"rx\")\n",
    "\n",
    "    tp = this_df[\"TP_universal\"].sum()\n",
    "    fp = this_df[\"FP_universal\"].sum()\n",
    "    tn = this_df[\"TN_universal\"].sum()\n",
    "    fn = this_df[\"FN_universal\"].sum()\n",
    "    uni_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(q, uni_accuracy,\"bx\")\n",
    "\n",
    "plt.plot(q, bf_accuracy, \"kx\", label = \"BF\")\n",
    "plt.plot(q, abs_accuracy, \"rx\", label = \"Method A\")\n",
    "plt.plot(q, uni_accuracy, \"bx\",label = \"Method B\")\n",
    "\n",
    "plt.xlabel(\"q\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"q_comp_1000N2.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad4c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tweak the code so that the analysis is added to the dataframes\n",
    "\n",
    "path_to_data = \"data/\"\n",
    "path_to_output = \"images/\"\n",
    "df1 = pd.read_csv(path_to_data + \"N_q_sims.rep_0.csv\")\n",
    "df2 = pd.read_csv(path_to_data +\"N_q_sims.rep_1.csv\")\n",
    "\n",
    "df1_q=df1[(df1[\"q\"]>0.01) & (df1[\"q\"]<0.011)]\n",
    "df2_q=df2[(df2[\"q\"]>0.01) & (df2[\"q\"]<0.011)]\n",
    "\n",
    "print(df1_q)\n",
    "\n",
    "## Create an output dataframe\n",
    "df1_q_output = df.copy()\n",
    "\n",
    "## Add in the columns for the results\n",
    "df1_q_output[\"TP_bf\"] = 0\n",
    "df1_q_output[\"TN_bf\"] = 0\n",
    "df1_q_output[\"FP_bf\"] = 0\n",
    "df1_q_output[\"FN_bf\"] = 0\n",
    "\n",
    "df1_q_output[\"TP_Method_A\"] = 0\n",
    "df1_q_output[\"TN_Method_A\"] = 0\n",
    "df1_q_output[\"FP_Method_A\"] = 0\n",
    "df1_q_output[\"FN_Method_A\"] = 0\n",
    "\n",
    "df1_q_output[\"TP_Method_B\"] = 0\n",
    "df1_q_output[\"TN_Method_B\"] = 0\n",
    "df1_q_output[\"FP_Method_B\"] = 0\n",
    "df1_q_output[\"FN_Method_B\"] = 0\n",
    "\n",
    "ns = set(df1_q[\"N\"].to_list())\n",
    "\n",
    "## Now we are updating the output dataframe\n",
    "\n",
    "df1_q_output[\"Method A\"] = df1_q_output[\"n\"]\n",
    "df1_q_output[\"Method A\"][df1_q_output[\"Method A\"]>0] = 1\n",
    "\n",
    "## Universal pipeline\n",
    "df1_q_output[\"Method B\"] = df1_q_output[\"n\"]\n",
    "df1_q_output[\"Method B\"].loc[df1_q_output[\"Method B\"]>0]=1\n",
    "df1_q_output[\"Method B\"].loc[(df1_q_output[\"nhom1\"]>0)|(df1_q_output[\"nhom2\"]>0)]=0\n",
    "\n",
    "df1_q_output[\"TP_bf\"].loc[(df1_q_output[\"log10BF\"]>=1) & (df1_q_output[\"mobile\"] > 0)] = 1\n",
    "df1_q_output[\"TN_bf\"].loc[(df1_q_output[\"log10BF\"]<1) & (df1_q_output[\"mobile\"] == 0)] = 1\n",
    "df1_q_output[\"FP_bf\"].loc[(df1_q_output[\"log10BF\"]>=1) & (df1_q_output[\"mobile\"] == 0)] = 1\n",
    "df1_q_output[\"FN_bf\"].loc[(df1_q_output[\"log10BF\"]<1) & (df1_q_output[\"mobile\"] > 0)] = 1\n",
    "\n",
    "df1_q_output[\"TP_Method_A\"].loc[(df1_q_output[\"Method A\"]>0) & (df1_q_output[\"mobile\"] > 0)] = 1\n",
    "df1_q_output[\"TN_Method_A\"].loc[(df1_q_output[\"Method A\"]==0) & (df1_q_output[\"mobile\"] == 0)] = 1\n",
    "df1_q_output[\"FP_Method_A\"].loc[(df1_q_output[\"Method A\"]>0) & (df1_q_output[\"mobile\"] == 0)] = 1\n",
    "df1_q_output[\"FN_Method_A\"].loc[(df1_q_output[\"Method A\"]==0) & (df1_q_output[\"mobile\"] > 0)] = 1\n",
    "\n",
    "df1_q_output[\"TP_Method_B\"].loc[(df1_q_output[\"mobile\"]>0) & (df1_q_output[\"Method B\"]>=1)] = 1\n",
    "df1_q_output[\"TN_Method_B\"].loc[(df1_q_output[\"mobile\"]==0) & (df1_q_output[\"Method B\"]<1)] = 1\n",
    "df1_q_output[\"FP_Method_B\"].loc[(df1_q_output[\"mobile\"]>0) & (df1_q_output[\"Method B\"]<1)] = 1\n",
    "df1_q_output[\"FN_Method_B\"].loc[(df1_q_output[\"mobile\"]==0) & (df1_q_output[\"Method B\"]>=1)] = 1\n",
    "\n",
    "## Run the plots\n",
    "for n in qs:\n",
    "    df_slice = df1_q_output[df1_q_output[\"q\"]==n]\n",
    "    tp = df_slice[\"TP_bf\"].sum()\n",
    "    fp = df_slice[\"FP_bf\"].sum()\n",
    "    tn = df_slice[\"TN_bf\"].sum()\n",
    "    fn = df_slice[\"FN_bf\"].sum()\n",
    "    bf_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(n, bf_accuracy,\"kx\")\n",
    "\n",
    "    tp = df_slice[\"TP_Method_A\"].sum()\n",
    "    fp = df_slice[\"FP_Method_A\"].sum()\n",
    "    tn = df_slice[\"TN_Method_A\"].sum()\n",
    "    fn = df_slice[\"FN_Method_A\"].sum()\n",
    "    abs_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(n, abs_accuracy,\"rx\")\n",
    "\n",
    "    tp = df_slice[\"TP_Method_B\"].sum()\n",
    "    fp = df_slice[\"FP_Method_B\"].sum()\n",
    "    tn = df_slice[\"TN_Method_B\"].sum()\n",
    "    fn = df_slice[\"FN_Method_B\"].sum()\n",
    "    uni_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(n, uni_accuracy,\"bx\")\n",
    "\n",
    "plt.plot(n, bf_accuracy, \"kx\", label = \"BF\")\n",
    "plt.plot(n, abs_accuracy, \"rx\", label = \"Method A\")\n",
    "plt.plot(n, uni_accuracy, \"bx\",label = \"Method B\")\n",
    "\n",
    "plt.xlabel(\"N\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"N_comp_p01q.png\",dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tp = this_df[\"TP_bf\"].sum()\n",
    "fp = this_df[\"FP_bf\"].sum()\n",
    "tn = this_df[\"TN_bf\"].sum()\n",
    "fn = this_df[\"FN_bf\"].sum()\n",
    "bf_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "plt.plot(n, bf_accuracy,\"kx\")\n",
    "\n",
    "tp = this_df[\"TP_class\"].sum()\n",
    "fp = this_df[\"FP_class\"].sum()\n",
    "tn = this_df[\"TN_class\"].sum()\n",
    "fn = this_df[\"FN_class\"].sum()\n",
    "abs_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "plt.plot(n, abs_accuracy,\"rx\")\n",
    "\n",
    "tp = this_df[\"TP_universal\"].sum()\n",
    "fp = this_df[\"FP_universal\"].sum()\n",
    "tn = this_df[\"TN_universal\"].sum()\n",
    "fn = this_df[\"FN_universal\"].sum()\n",
    "uni_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "plt.plot(n, uni_accuracy,\"bx\")\n",
    "\n",
    "plt.plot(n, bf_accuracy, \"kx\", label = \"BF\")\n",
    "plt.plot(n, abs_accuracy, \"rx\", label = \"Method A\")\n",
    "plt.plot(n, uni_accuracy, \"bx\",label = \"Method B\")\n",
    "\n",
    "plt.xlabel(\"N\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"N_comp_p01q.png\",dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_q_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_q_output.to_csv(\"df1_N1000_full.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce78624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import configparser\n",
    "import json\n",
    "from distutils.util import strtobool\n",
    "## Script to run data and analysis in one go\n",
    "\n",
    "## Function definitions\n",
    "## Define the main functions\n",
    "def safebeta(N,n, alpha,beta):\n",
    "    facterm = 1.0\n",
    "    if alpha>1:\n",
    "        a = np.arange(1, alpha)\n",
    "        facterm = np.prod((n+a)/(N+a))\n",
    "    if beta > 1.0:\n",
    "        a = np.arange(1, beta)\n",
    "        facterm = facterm * np.prod((N-n+a)/(N+alpha+a))\n",
    "    return facterm / (N+alpha)\n",
    "\n",
    "safebeta = np.vectorize(safebeta)\n",
    "\n",
    "## Function to calculate the posterior ratio\n",
    "def fasterpostN2(Nhomo1,nhomo1,Nhomo2,nhomo2,N,n,nmax):\n",
    "    N = int(N)\n",
    "    alpha1 = nhomo1+1\n",
    "    beta1 = Nhomo1-nhomo1+1\n",
    "    alpha2 = nhomo2+1\n",
    "    beta2 = Nhomo2-nhomo2+1\n",
    "    postN2 = np.zeros(N+2)\n",
    "    postN2xN2 = np.zeros(N+2)\n",
    "    PN2max = -10.0\n",
    "    N2max = 0\n",
    "    for N2 in np.arange(0,min(N+1,n+nmax+1)):\n",
    "        N2 = int(N2)\n",
    "        i = N2 + 1\n",
    "        n2_min = max(0,N2-n)\n",
    "        n2_max = min(N-n, N2)\n",
    "        n2_array = np.arange(n2_min, n2_max+1)\n",
    "        postN2[i] = np.sum(safebeta(N-N2,n-N2+n2_array,alpha1,beta1) * safebeta(N2,n2_array,alpha2,beta2))\n",
    "        postN2[i]=postN2[i]/i\n",
    "        if (N2>0) & (postN2[i]>PN2max):\n",
    "            PN2max = postN2[i]\n",
    "            N2max = N2\n",
    "        \n",
    "        postN2xN2[i]=postN2[i]*N2\n",
    "    \n",
    "    sumpostN2=sum(postN2)\n",
    "    if sumpostN2 != 0:\n",
    "        postN2=postN2/sumpostN2\n",
    "        postN2xN2=postN2xN2/sumpostN2\n",
    "        logBF21N2 = np.log10(postN2[N2max+1]/postN2[1]) # +1 because of the index\n",
    "        meanN2=sum(postN2xN2)\n",
    "        results = [meanN2,N2max,logBF21N2]\n",
    "        results = logBF21N2\n",
    "    else:\n",
    "        ## If sumpost = 0, can't calculate BF. Return nan\n",
    "         results = [np.nan, np.nan, np.nan]\n",
    "         results = np.nan\n",
    "    return results\n",
    "fasterpostN2 = np.vectorize(fasterpostN2)\n",
    "## Function to create sequencing errors\n",
    "def create_errors(row, q):\n",
    "        rand_numbs = np.random.rand(int(row))\n",
    "        nhom1 = (rand_numbs < q).sum()\n",
    "        return int(nhom1)\n",
    "\n",
    "## Input the parameters - what should we be able to vary? \n",
    "## These should be lists\n",
    "config = configparser.ConfigParser()\n",
    "config.read('parameters.cfg')\n",
    "N_values = json.loads(config.get(\"Simulation parameters\",\"N_values\"))\n",
    "Nhom1_values = json.loads(config.get(\"Simulation parameters\",\"Nhom1_values\"))\n",
    "Nhom2_values = json.loads(config.get(\"Simulation parameters\",\"Nhom2_values\"))\n",
    "q_values = json.loads(config.get(\"Simulation parameters\",\"q_values\"))\n",
    "N2_values = json.loads(config.get(\"Simulation parameters\",\"N2_values\")) \n",
    "\n",
    "## Check if the homografts should have separate read depths. Else make them the same as the heterografts\n",
    "constant_Nhom = bool(strtobool((config.get(\"Simulation parameters\",\"constant_Nhom\"))))\n",
    "\n",
    "if constant_Nhom: \n",
    "    constant_Nhom_value = int(config.get(\"Simulation parameters\",\"constant_Nhom_value\"))\n",
    "## This is the value the error and N is multiplied by\n",
    "\n",
    "## Set the random flags\n",
    "random_N = bool(strtobool((config.get(\"Simulation parameters\",\"random_N\"))))\n",
    "random_Nhom = bool(strtobool((config.get(\"Simulation parameters\",\"random_Nhom\"))))\n",
    "random_q = bool(strtobool((config.get(\"Simulation parameters\",\"random_q\"))))\n",
    "\n",
    "## These should be integers\n",
    "no_transcripts = int(config.get(\"Simulation parameters\",\"no_transcripts\"))\n",
    "\n",
    "## Create iterations of all parameter values\n",
    "settings_list = [N_values, Nhom1_values, Nhom2_values, q_values, N2_values]\n",
    "data = (list(itertools.product(*settings_list)))\n",
    "df = pd.DataFrame(data, columns = ['N','q',\"N2_func\"])\n",
    "df = pd.concat([df]*no_transcripts)\n",
    "\n",
    "if constant_Nhom:\n",
    "    df[\"Nhom1\"] = constant_Nhom_value\n",
    "    df[\"Nhom2\"] = constant_Nhom_value\n",
    "else:\n",
    "    df[\"Nhom1\"] = df[\"N\"]\n",
    "    df[\"Nhom2\"] = df[\"N\"]\n",
    "\n",
    "## Define our mobile transcripts - each transcript should have one unique definition which is kept the same for all parameter values\n",
    "mobile_def = random.choices([True, False], weights=[0.5, 0.5], k=no_transcripts)\n",
    "mobile_def = np.repeat(mobile_def, len(data))\n",
    "df[\"mobile\"] = mobile_def\n",
    "\n",
    "## Apply random flags (if appropriate)\n",
    "if random_N:\n",
    "    df[\"N\"] = df[\"N\"].apply(lambda x: np.random.randint(low = 10, high = x))\n",
    "if random_Nhom:\n",
    "    df[\"Nhom1\"] = df[\"Nhom1\"].apply(lambda x: np.random.randint(low = 10, high = x))\n",
    "    df[\"Nhom2\"] = df[\"Nhom2\"].apply(lambda x: np.random.randint(low = 10, high = x))\n",
    "if random_q:\n",
    "    df[\"q\"] = df[\"q\"].apply(lambda x: np.random.uniform(low = 0, high = x))\n",
    "\n",
    "## Create the sequencing errors\n",
    "df[\"nhom1\"] = df.apply(lambda x: create_errors(x.Nhom1, x.q),axis=1)\n",
    "df[\"nhom2\"] = df.apply(lambda x: create_errors(x.Nhom2, x.q),axis = 1)\n",
    "df[\"n\"] = df.apply(lambda x: create_errors(x.N, x.q), axis = 1)\n",
    "df[\"N2\"] = df[\"N2_func\"] * df[\"mobile\"] * df[\"q\"] * df[\"N\"]\n",
    "\n",
    "df[\"n\"] = df[\"n\"] + df[\"N2\"]\n",
    "\n",
    "## Run Bayes analysis\n",
    "df[\"log10BF\"] = df.apply(lambda x: fasterpostN2(x.Nhom1,x.nhom1,x.Nhom2,x.nhom2,x.N,x.n,10), axis=1)\n",
    "\n",
    "## Run the analysis for Method A and Method B\n",
    "## Add in the columns for the results\n",
    "df[\"TP_bf\"] = 0\n",
    "df[\"TN_bf\"] = 0\n",
    "df[\"FP_bf\"] = 0\n",
    "df[\"FN_bf\"] = 0\n",
    "\n",
    "df[\"TP_Method_A\"] = 0\n",
    "df[\"TN_Method_A\"] = 0\n",
    "df[\"FP_Method_A\"] = 0\n",
    "df[\"FN_Method_A\"] = 0\n",
    "\n",
    "df[\"TP_Method_B\"] = 0\n",
    "df[\"TN_Method_B\"] = 0\n",
    "df[\"FP_Method_B\"] = 0\n",
    "df[\"FN_Method_B\"] = 0\n",
    "\n",
    "## Now we are updating the output dataframe\n",
    "df[\"Method A\"] = df[\"n\"]\n",
    "df[\"Method A\"][df[\"Method A\"]>0] = 1\n",
    "\n",
    "## Universal pipeline\n",
    "df[\"Method B\"] = df[\"n\"]\n",
    "df[\"Method B\"].loc[df[\"Method B\"]>0]=1\n",
    "df[\"Method B\"].loc[(df[\"nhom1\"]>0)|(df[\"nhom2\"]>0)]=0\n",
    "\n",
    "df[\"TP_bf\"].loc[(df[\"log10BF\"]>=1) & (df[\"mobile\"] > 0)] = 1\n",
    "df[\"TN_bf\"].loc[(df[\"log10BF\"]<1) & (df[\"mobile\"] == 0)] = 1\n",
    "df[\"FP_bf\"].loc[(df[\"log10BF\"]>=1) & (df[\"mobile\"] == 0)] = 1\n",
    "df[\"FN_bf\"].loc[(df[\"log10BF\"]<1) & (df[\"mobile\"] > 0)] = 1\n",
    "\n",
    "df[\"TP_Method_A\"].loc[(df[\"Method A\"]>0) & (df[\"mobile\"] > 0)] = 1\n",
    "df[\"TN_Method_A\"].loc[(df[\"Method A\"]==0) & (df[\"mobile\"] == 0)] = 1\n",
    "df[\"FP_Method_A\"].loc[(df[\"Method A\"]>0) & (df[\"mobile\"] == 0)] = 1\n",
    "df[\"FN_Method_A\"].loc[(df[\"Method A\"]==0) & (df[\"mobile\"] > 0)] = 1\n",
    "\n",
    "df[\"TP_Method_B\"].loc[(df[\"mobile\"]>0) & (df[\"Method B\"]>=1)] = 1\n",
    "df[\"TN_Method_B\"].loc[(df[\"mobile\"]==0) & (df[\"Method B\"]<1)] = 1\n",
    "df[\"FP_Method_B\"].loc[(df[\"mobile\"]>0) & (df[\"Method B\"]<1)] = 1\n",
    "df[\"FN_Method_B\"].loc[(df[\"mobile\"]==0) & (df[\"Method B\"]>=1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d381151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "## Plot the data\n",
    "## Choose the parameters of interest: can only vary one parameter\n",
    "\n",
    "fixed_q = 0.01\n",
    "fixed_N2 = 5\n",
    "\n",
    "## Choose the correct section of the dataframe\n",
    "df_slice = df[(df[\"N2_func\"] == fixed_N2) & (df[\"q\"]==fixed_q)]\n",
    "## Get the list of N values (we are varying N)\n",
    "\n",
    "Ns = set(df_slice[\"N\"].to_list())\n",
    "\n",
    "for N in Ns:\n",
    "    ## Choose the same hom values\n",
    "    this_df = df_slice[(df_slice[\"N\"]==N) & (df_slice[\"Nhom1\"]==N) & (df_slice[\"Nhom2\"]==N)]\n",
    "    print(this_df)\n",
    "    tp = this_df[\"TP_bf\"].sum()\n",
    "    fp = this_df[\"FP_bf\"].sum()\n",
    "    tn = this_df[\"TN_bf\"].sum()\n",
    "    fn = this_df[\"FN_bf\"].sum()\n",
    "    bf_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(N, bf_accuracy,\"kx\")\n",
    "\n",
    "    tp = this_df[\"TP_Method_A\"].sum()\n",
    "    fp = this_df[\"FP_Method_A\"].sum()\n",
    "    tn = this_df[\"TN_Method_A\"].sum()\n",
    "    fn = this_df[\"FN_Method_A\"].sum()\n",
    "    abs_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(N, abs_accuracy,\"rx\")\n",
    "\n",
    "    tp = this_df[\"TP_Method_B\"].sum()\n",
    "    fp = this_df[\"FP_Method_B\"].sum()\n",
    "    tn = this_df[\"TN_Method_B\"].sum()\n",
    "    fn = this_df[\"FN_Method_B\"].sum()\n",
    "    uni_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    plt.plot(N, uni_accuracy,\"bx\")\n",
    "\n",
    "plt.plot(N, bf_accuracy, \"kx\", label = \"BF\")\n",
    "plt.plot(N, abs_accuracy, \"rx\", label = \"Method A\")\n",
    "plt.plot(N, uni_accuracy, \"bx\",label = \"Method B\")\n",
    "\n",
    "plt.xlabel(\"N\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"N_comp_p01q.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002d10f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bf_calculator.baymobil' has no attribute 'create_simulated_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/tomkinsm/bf_calculator/create_figures.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomkinsm/bf_calculator/create_figures.ipynb#ch0000038?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbf_calculator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbaymobil\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbaymob\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomkinsm/bf_calculator/create_figures.ipynb#ch0000038?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplot_data\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplotdata\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tomkinsm/bf_calculator/create_figures.ipynb#ch0000038?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m baymob\u001b[39m.\u001b[39;49mcreate_simulated_data()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomkinsm/bf_calculator/create_figures.ipynb#ch0000038?line=4'>5</a>\u001b[0m plotdata\u001b[39m.\u001b[39mplot_data(df,\u001b[39m\"\u001b[39m\u001b[39mq\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'bf_calculator.baymobil' has no attribute 'create_simulated_data'"
     ]
    }
   ],
   "source": [
    "import bf_calculator.baymobil as baymob\n",
    "import plot_data as plotdata\n",
    "\n",
    "df = baymob.create_simulated_data()\n",
    "plotdata.plot_data(df,\"q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418246fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4036c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
